{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7aec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transform\n",
    "import torchmetrics\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as matplot\n",
    "\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "from torch.utils.data import DataLoader, Subset, random_split, ConcatDataset\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='rock-paper-scissors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "data_dir = './dataset'\n",
    "print(os.listdir(data_dir))\n",
    "\n",
    "# Classes\n",
    "# Place all the images according to there class in 3 different folders (Rock, Paper, Scissors)\n",
    "classes = os.listdir(data_dir)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb730e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "# Transform for training dataset\n",
    "train_transform = transform.Compose([\n",
    "                         transform.Resize((32,32)), \n",
    "                         transform.RandomHorizontalFlip(), \n",
    "                         transform.ToTensor(), \n",
    "                         transform.Normalize(*stats,inplace=True)])\n",
    "\n",
    "# Transform for validation dataset\n",
    "valid_transform = transform.Compose([transform.Resize((32,32)),transform.ToTensor(), transform.Normalize(*stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete data (Includes images from four datasets)\n",
    "rock_paper_scissors_data = ImageFolder(data_dir, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee047326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diving the dataset in the ratio of 85% and 15%\n",
    "# Training dataset - 85%\n",
    "# Validation dataset - 15%\n",
    "train_size = int(0.85 * len(rock_paper_scissors_data))\n",
    "val_size = len(rock_paper_scissors_data) - train_size\n",
    "train_dataset, val_dataset = random_split(rock_paper_scissors_data, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88597fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Size\n",
    "batch_size = 64\n",
    "\n",
    "# Number of classes (3)\n",
    "# Rock, Paper, Scissors\n",
    "num_of_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom validation dataset from university\n",
    "# **Remove custom_val_dataset if you are not using any custom dataset**\n",
    "custom_val_dataset = ImageFolder(\"./custom-dataset/validation\", valid_transform)\n",
    "\n",
    "# Merging the custom validation dataset with the validation dataset\n",
    "complete_val_dataset = ConcatDataset([val_dataset,custom_val_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom test dataset from university\n",
    "test_dataset = ImageFolder(\"./custom-dataset/test\", valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df173b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders for train, test & validation\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "val_dataloader = DataLoader(complete_val_dataset, batch_size=batch_size, num_workers=3, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08643155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show images\n",
    "def show_images(dataloader):\n",
    "    for images, labels in dataloader:\n",
    "        fig, ax = matplot.subplots(figsize=(12, 12))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc30f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the device GPU or CPU\n",
    "# Install Cuda if you want use GPU\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "# Function to move the data on to the device\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79728bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836bb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet9 model\n",
    "\n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = conv_block(3, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True)\n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(512, num_classes))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out)\n",
    "        out = self.classifier(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = Number of folds\n",
    "k = 10\n",
    "number_of_epochs = 8\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3304b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-1 Score\n",
    "def get_f1score(preds, labels):\n",
    "    f1_score = F1Score(task=\"multiclass\", num_classes=num_of_classes, average='weighted')\n",
    "    return f1_score(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def get_accuracy(preds, labels):\n",
    "    accuracy = Accuracy(task=\"multiclass\", num_classes=num_of_classes).to(device)\n",
    "    return accuracy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a37e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc96273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    return all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9bde9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without K-fold cross-validation\n",
    "    \n",
    "# Model\n",
    "model = ResNet9()\n",
    "model.to(device)\n",
    "    \n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "# To store training losses and accuracies\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "    \n",
    "# To store validation losses and accuracies\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "    \n",
    "# Train and validate\n",
    "for epoch in range(number_of_epochs):\n",
    "    train_loss = train(model, train_dataloader, criterion, optimizer)\n",
    "    val_loss = train(model,val_dataloader,criterion,optimizer)\n",
    "        \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "        \n",
    "    # Training Accuracy\n",
    "    preds, labels = evaluate(model, train_dataloader)\n",
    "    train_accuracy = get_accuracy(preds, labels)\n",
    "\n",
    "    # Validation Accuracy\n",
    "    preds, labels = evaluate(model, val_dataloader)\n",
    "    val_accuracy = get_accuracy(preds, labels)\n",
    "\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "        \n",
    "    print(f'Epoch {epoch + 1} - Train loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Val loss: {val_loss:.4f} - Val accuracy: {val_accuracy:.4f}')\n",
    "    \n",
    "# Saving the Current Fold Model\n",
    "torch.save(model, f'withoutKFold.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross-validation\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Train and validate for each fold\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(rock_paper_scissors_data)):\n",
    "    print(f'Fold {fold + 1}/{k}')\n",
    "    \n",
    "    # Create subset datasets and dataloaders for this fold\n",
    "    train_subset = Subset(rock_paper_scissors_data, train_indices)\n",
    "    val_subset = Subset(rock_paper_scissors_data, val_indices) + custom_val_dataset\n",
    "    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Model\n",
    "    model = ResNet9()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "    # To store training losses and accuracies\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "        \n",
    "    # To store validation losses and accuracies\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Train and validate for this fold\n",
    "    for epoch in range(number_of_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer)\n",
    "        val_loss = train(model,val_loader,criterion,optimizer)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Training Accuracy\n",
    "        preds, labels = evaluate(model, train_loader)\n",
    "        train_accuracy = get_accuracy(preds, labels)\n",
    "\n",
    "        # Validation Accuracy\n",
    "        preds, labels = evaluate(model, val_loader)\n",
    "        val_accuracy = get_accuracy(preds, labels)\n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        print(f'Epoch {epoch + 1} - Train loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Val loss: {val_loss:.4f} - Val accuracy: {val_accuracy:.4f}')\n",
    "    \n",
    "    # Saving the Current Fold Model\n",
    "    torch.save(model, f'fold{fold}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cfac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the losses\n",
    "def plot_losses():\n",
    "    matplot.plot(train_losses, '-bx')\n",
    "    matplot.plot(val_losses, '-rx')\n",
    "    matplot.xlabel('epoch')\n",
    "    matplot.ylabel('loss')\n",
    "    matplot.legend(['Training', 'Validation'])\n",
    "    matplot.title('Loss vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c9d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "test_model = ResNet9()\n",
    "PATH = './model/10Fold-40Epochs-Dropout0.2/fold2.pth'\n",
    "test_model = torch.load(PATH)\n",
    "test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96724dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluating Test Data\n",
    "preds, labels = evaluate(test_model, test_dataloader)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = get_accuracy(preds, labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-1 SCORE\n",
    "f1_score = get_f1score(preds, labels)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c1453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "confusion_matrix = np.zeros((num_of_classes, num_of_classes))\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(test_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = test_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d4f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplot.figure(figsize=(12,7))\n",
    "df_cm = pd.DataFrame(confusion_matrix, index=classes, columns=classes)\n",
    "heatmap = sn.heatmap(df_cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
