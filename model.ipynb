{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7aec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transform\n",
    "import torchmetrics\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as matplot\n",
    "\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "from torch.utils.data import DataLoader, Subset, random_split, ConcatDataset\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db4a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='rock-paper-scissors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e726e551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paper', 'rock', 'scissors']\n",
      "['paper', 'rock', 'scissors']\n"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "data_dir = './dataset'\n",
    "print(os.listdir(data_dir))\n",
    "\n",
    "# Classes\n",
    "# Place all the images according to there class in 3 different folders (Rock, Paper, Scissors)\n",
    "classes = os.listdir(data_dir)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb730e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "# Transform for training dataset\n",
    "train_transform = transform.Compose([\n",
    "                         transform.Resize((32,32)), \n",
    "                         transform.RandomHorizontalFlip(), \n",
    "                         transform.ToTensor(), \n",
    "                         transform.Normalize(*stats,inplace=True)])\n",
    "\n",
    "# Transform for validation dataset\n",
    "valid_transform = transform.Compose([transform.Resize((32,32)),transform.ToTensor(), transform.Normalize(*stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa4e4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete data (Includes images from four datasets)\n",
    "rock_paper_scissors_data = ImageFolder(data_dir, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee047326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diving the dataset in the ratio of 85% and 15%\n",
    "# Training dataset - 85%\n",
    "# Validation dataset - 15%\n",
    "train_size = int(0.85 * len(rock_paper_scissors_data))\n",
    "val_size = len(rock_paper_scissors_data) - train_size\n",
    "train_dataset, val_dataset = random_split(rock_paper_scissors_data, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88597fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Size\n",
    "batch_size = 64\n",
    "\n",
    "# Number of classes (3)\n",
    "# Rock, Paper, Scissors\n",
    "num_of_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8f5c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom validation dataset from university\n",
    "# **Remove custom_val_dataset if you are not using any custom dataset**\n",
    "custom_val_dataset = ImageFolder(\"./custom-dataset/validation\", valid_transform)\n",
    "\n",
    "# Merging the custom validation dataset with the validation dataset\n",
    "complete_val_dataset = ConcatDataset([val_dataset,custom_val_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facf2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom test dataset from university\n",
    "test_dataset = ImageFolder(\"./custom-dataset/test\", valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4df173b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders for train, test & validation\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "val_dataloader = DataLoader(complete_val_dataset, batch_size=batch_size, num_workers=3, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08643155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show images\n",
    "def show_images(dataloader):\n",
    "    for images, labels in dataloader:\n",
    "        fig, ax = matplot.subplots(figsize=(12, 12))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcc30f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the device GPU or CPU\n",
    "# Install Cuda if you want use GPU\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "# Function to move the data on to the device\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79728bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "836bb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet9 model\n",
    "\n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = conv_block(3, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True)\n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Dropout(0.1),\n",
    "                                        nn.Linear(512, num_classes))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out)\n",
    "        out = self.classifier(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f5d81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = Number of folds\n",
    "k = 10\n",
    "number_of_epochs = 40\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a3304b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-1 Score\n",
    "def get_f1score(preds, labels):\n",
    "    f1_score = F1Score(task=\"multiclass\", num_classes=num_of_classes, average='weighted')\n",
    "    return f1_score(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80ce2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def get_accuracy(preds, labels):\n",
    "    accuracy = Accuracy(task=\"multiclass\", num_classes=num_of_classes).to(device)\n",
    "    return accuracy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a37e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edc96273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    return all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9bde9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without K-fold cross-validation\n",
    "    \n",
    "# Model\n",
    "\n",
    "model = ResNet9()\n",
    "model.to(device)\n",
    "    \n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "    \n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "    \n",
    "# Train and validate for this fold\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "    train_loss = train(model, train_dataloader, criterion, optimizer)\n",
    "    val_loss = train(model,val_dataloader,criterion,optimizer)\n",
    "        \n",
    "    # Loss\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "        \n",
    "    preds, labels = evaluate(model, train_dataloader)\n",
    "    train_accuracy = get_accuracy(preds, labels)\n",
    "\n",
    "    preds, labels = evaluate(model, val_dataloader)\n",
    "    val_accuracy = get_accuracy(preds, labels)\n",
    "\n",
    "    # Accuracies\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "        \n",
    "    print(f'Epoch {epoch + 1} - Train loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Val loss: {val_loss:.4f} - Val accuracy: {val_accuracy:.4f}')\n",
    "    \n",
    "# Saving the Current Fold Model\n",
    "torch.save(model, f'withoutKFold.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1926f8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n",
      "Epoch 1 - Train loss: 0.5172 - Train Accuracy: 0.3376 - Val loss: 4.8280 - Val accuracy: 0.3200\n",
      "Epoch 2 - Train loss: 1.0915 - Train Accuracy: 0.4867 - Val loss: 3.4561 - Val accuracy: 0.4335\n",
      "Epoch 3 - Train loss: 0.7563 - Train Accuracy: 0.6016 - Val loss: 2.5221 - Val accuracy: 0.5436\n",
      "Epoch 4 - Train loss: 0.4713 - Train Accuracy: 0.6127 - Val loss: 2.3100 - Val accuracy: 0.5550\n",
      "Epoch 5 - Train loss: 0.3626 - Train Accuracy: 0.5841 - Val loss: 2.2104 - Val accuracy: 0.5356\n",
      "Epoch 6 - Train loss: 0.3668 - Train Accuracy: 0.5084 - Val loss: 2.0912 - Val accuracy: 0.4702\n",
      "Epoch 7 - Train loss: 0.3037 - Train Accuracy: 0.5111 - Val loss: 2.1218 - Val accuracy: 0.4759\n",
      "Epoch 8 - Train loss: 0.3132 - Train Accuracy: 0.6485 - Val loss: 1.9161 - Val accuracy: 0.5952\n",
      "Epoch 9 - Train loss: 0.2470 - Train Accuracy: 0.6658 - Val loss: 1.7687 - Val accuracy: 0.6227\n",
      "Epoch 10 - Train loss: 0.2973 - Train Accuracy: 0.6698 - Val loss: 1.3367 - Val accuracy: 0.6193\n",
      "Epoch 11 - Train loss: 0.2042 - Train Accuracy: 0.6575 - Val loss: 1.1733 - Val accuracy: 0.6112\n",
      "Epoch 12 - Train loss: 0.1720 - Train Accuracy: 0.8173 - Val loss: 0.8769 - Val accuracy: 0.7626\n",
      "Epoch 13 - Train loss: 0.1311 - Train Accuracy: 0.8439 - Val loss: 0.6382 - Val accuracy: 0.7970\n",
      "Epoch 14 - Train loss: 0.1209 - Train Accuracy: 0.8497 - Val loss: 0.5092 - Val accuracy: 0.8050\n",
      "Epoch 15 - Train loss: 0.0927 - Train Accuracy: 0.9088 - Val loss: 0.4016 - Val accuracy: 0.8567\n",
      "Epoch 16 - Train loss: 0.0733 - Train Accuracy: 0.8768 - Val loss: 0.3987 - Val accuracy: 0.8291\n",
      "Epoch 17 - Train loss: 0.0677 - Train Accuracy: 0.9190 - Val loss: 0.2816 - Val accuracy: 0.8853\n",
      "Epoch 18 - Train loss: 0.0547 - Train Accuracy: 0.9131 - Val loss: 0.2771 - Val accuracy: 0.8635\n",
      "Epoch 19 - Train loss: 0.0428 - Train Accuracy: 0.9676 - Val loss: 0.2578 - Val accuracy: 0.9300\n",
      "Epoch 20 - Train loss: 0.0507 - Train Accuracy: 0.9483 - Val loss: 0.1267 - Val accuracy: 0.8979\n",
      "Epoch 21 - Train loss: 0.0364 - Train Accuracy: 0.9673 - Val loss: 0.0971 - Val accuracy: 0.9209\n",
      "Epoch 22 - Train loss: 0.0225 - Train Accuracy: 0.9904 - Val loss: 0.0729 - Val accuracy: 0.9461\n",
      "Epoch 23 - Train loss: 0.0120 - Train Accuracy: 0.9953 - Val loss: 0.0515 - Val accuracy: 0.9553\n",
      "Epoch 24 - Train loss: 0.0109 - Train Accuracy: 0.9985 - Val loss: 0.0448 - Val accuracy: 0.9587\n",
      "Epoch 25 - Train loss: 0.0061 - Train Accuracy: 0.9963 - Val loss: 0.0247 - Val accuracy: 0.9553\n",
      "Epoch 26 - Train loss: 0.0035 - Train Accuracy: 0.9976 - Val loss: 0.0315 - Val accuracy: 0.9576\n",
      "Epoch 27 - Train loss: 0.0048 - Train Accuracy: 0.9987 - Val loss: 0.0224 - Val accuracy: 0.9633\n",
      "Epoch 28 - Train loss: 0.0061 - Train Accuracy: 0.9828 - Val loss: 0.0251 - Val accuracy: 0.9495\n",
      "Epoch 29 - Train loss: 0.0053 - Train Accuracy: 0.9911 - Val loss: 0.0414 - Val accuracy: 0.9518\n",
      "Epoch 30 - Train loss: 0.0038 - Train Accuracy: 0.9984 - Val loss: 0.0186 - Val accuracy: 0.9644\n",
      "Epoch 31 - Train loss: 0.0030 - Train Accuracy: 0.9917 - Val loss: 0.0249 - Val accuracy: 0.9415\n",
      "Epoch 32 - Train loss: 0.0021 - Train Accuracy: 0.9997 - Val loss: 0.0121 - Val accuracy: 0.9656\n",
      "Epoch 33 - Train loss: 0.0012 - Train Accuracy: 0.9999 - Val loss: 0.0110 - Val accuracy: 0.9633\n",
      "Epoch 34 - Train loss: 0.0013 - Train Accuracy: 0.9997 - Val loss: 0.0069 - Val accuracy: 0.9690\n",
      "Epoch 35 - Train loss: 0.0010 - Train Accuracy: 0.9990 - Val loss: 0.0069 - Val accuracy: 0.9644\n",
      "Epoch 36 - Train loss: 0.0007 - Train Accuracy: 1.0000 - Val loss: 0.0052 - Val accuracy: 0.9599\n",
      "Epoch 37 - Train loss: 0.0006 - Train Accuracy: 1.0000 - Val loss: 0.0038 - Val accuracy: 0.9622\n",
      "Epoch 38 - Train loss: 0.0008 - Train Accuracy: 1.0000 - Val loss: 0.0045 - Val accuracy: 0.9656\n",
      "Epoch 39 - Train loss: 0.0006 - Train Accuracy: 1.0000 - Val loss: 0.0036 - Val accuracy: 0.9587\n",
      "Epoch 40 - Train loss: 0.0005 - Train Accuracy: 1.0000 - Val loss: 0.0029 - Val accuracy: 0.9667\n",
      "Fold 2/10\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Train and validate for each fold\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(rock_paper_scissors_data)):\n",
    "    print(f'Fold {fold + 1}/{k}')\n",
    "    \n",
    "    if fold == 1:\n",
    "        break\n",
    "    \n",
    "    # Create subset datasets and dataloaders for this fold\n",
    "    train_subset = Subset(rock_paper_scissors_data, train_indices)\n",
    "    val_subset = Subset(rock_paper_scissors_data, val_indices) + custom_val_dataset\n",
    "    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Model\n",
    "    model = ResNet9()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "        \n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Train and validate for this fold\n",
    "    for epoch in range(number_of_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer)\n",
    "        val_loss = train(model,val_loader,criterion,optimizer)\n",
    "        \n",
    "        # Loss\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        preds, labels = evaluate(model, train_loader)\n",
    "        train_accuracy = get_accuracy(preds, labels)\n",
    "\n",
    "        preds, labels = evaluate(model, val_loader)\n",
    "        val_accuracy = get_accuracy(preds, labels)\n",
    "\n",
    "        # Accuracies\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        print(f'Epoch {epoch + 1} - Train loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Val loss: {val_loss:.4f} - Val accuracy: {val_accuracy:.4f}')\n",
    "    \n",
    "    # Saving the Current Fold Model\n",
    "    torch.save(model, f'fold{fold}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71cfac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the losses\n",
    "def plot_losses():\n",
    "    matplot.plot(train_losses, '-bx')\n",
    "    matplot.plot(val_losses, '-rx')\n",
    "    matplot.xlabel('epoch')\n",
    "    matplot.ylabel('loss')\n",
    "    matplot.legend(['Training', 'Validation'])\n",
    "    matplot.title('Loss vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c1a0de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7c9d1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet9(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res1): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res2): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the model\n",
    "test_model = ResNet9()\n",
    "PATH = './fold0.pth'\n",
    "test_model = torch.load(PATH)\n",
    "test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d96724dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6013, device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating Test Data\n",
    "preds, labels = evaluate(test_model, test_dataloader)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = get_accuracy(preds, labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-1 SCORE\n",
    "f1_score = get_f1score(preds, labels)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c1453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "confusion_matrix = np.zeros((num_of_classes, num_of_classes))\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(test_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = test_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "matplot.figure(figsize=(12,7))\n",
    "\n",
    "df_cm = pd.DataFrame((confusion_matrix/(np.sum(confusion_matrix, axis=1))), index=classes, columns=classes)\n",
    "heatmap = sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d4f8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
