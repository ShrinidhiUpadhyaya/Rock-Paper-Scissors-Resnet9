{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7aec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db4a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='rock-paper-scissors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e726e551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train', 'validation']\n",
      "['paper', 'rock', 'scissors']\n"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "data_dir = './dataset'\n",
    "print(os.listdir(data_dir))\n",
    "\n",
    "# Classes\n",
    "classes = os.listdir(data_dir + \"/train\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb730e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "train_tfms = tt.Compose([tt.CenterCrop(224),\n",
    "                         tt.Resize((32,32)), \n",
    "                         tt.RandomHorizontalFlip(), \n",
    "                         tt.ToTensor(), \n",
    "                         tt.Normalize(*stats,inplace=True)])\n",
    "\n",
    "valid_tfms = tt.Compose([tt.CenterCrop(224),tt.Resize((32,32)),tt.ToTensor(), tt.Normalize(*stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa4e4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "train_dataset = ImageFolder(data_dir+'/train', train_tfms)\n",
    "valid_dataset = ImageFolder(data_dir+'/validation', valid_tfms)\n",
    "test_dataset = ImageFolder(data_dir+'/test', valid_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ebbef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88597fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_of_classes = len(classes)\n",
    "num_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15316eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08643155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(dataloader):\n",
    "    for images, labels in dataloader:\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcc30f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79728bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "740b583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Dataset on the device('Cuda' if available)\n",
    "train_dataloader = DeviceDataLoader(train_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNet9 model\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet9, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "#         self.fc = nn.Linear(512, 3)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.MaxPool2d(4),\n",
    "                                nn.Flatten(), \n",
    "                                nn.Dropout(0.2),\n",
    "                                nn.Linear(512, num_of_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "#         x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a293160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallResNet9(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallResNet9, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "#         self.fc = nn.Linear(256, num_of_classes)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.MaxPool2d(4), \n",
    "                      nn.Flatten(), \n",
    "                      nn.Dropout(0.2),\n",
    "                      nn.Linear(256, num_of_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "#         x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f5d81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "number_of_epochs = 100\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a37e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909c1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluation function\n",
    "# def evaluate(model, val_loader):\n",
    "#     model.eval()\n",
    "#     all_labels = []\n",
    "#     all_preds = []\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in val_loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             all_labels.append(labels.cpu().numpy())\n",
    "#             all_preds.append(preds.cpu().numpy())\n",
    "#     all_labels = np.concatenate(all_labels)\n",
    "#     all_preds = np.concatenate(all_preds)\n",
    "#     accuracy = accuracy_score(all_labels, all_preds)\n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "843c1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    accuracy = Accuracy(task=\"multiclass\", num_classes=num_of_classes).to(device)\n",
    "    return accuracy(all_preds, all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1926f8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/3\n",
      "Epoch 1 - Train loss: 0.9592 - Val loss: 1.3148 - Val accuracy: 0.3298\n",
      "Epoch 2 - Train loss: 1.2120 - Val loss: 1.2169 - Val accuracy: 0.3330\n",
      "Epoch 3 - Train loss: 0.9275 - Val loss: 1.2209 - Val accuracy: 0.3995\n",
      "Epoch 4 - Train loss: 0.8450 - Val loss: 1.2088 - Val accuracy: 0.5613\n",
      "Epoch 5 - Train loss: 0.7494 - Val loss: 1.1723 - Val accuracy: 0.6675\n",
      "Epoch 6 - Train loss: 0.6982 - Val loss: 1.1361 - Val accuracy: 0.6738\n",
      "Epoch 7 - Train loss: 0.6933 - Val loss: 1.0679 - Val accuracy: 0.6901\n",
      "Epoch 8 - Train loss: 0.6799 - Val loss: 1.0870 - Val accuracy: 0.7466\n",
      "Epoch 9 - Train loss: 0.6727 - Val loss: 1.0505 - Val accuracy: 0.6199\n",
      "Epoch 10 - Train loss: 0.6471 - Val loss: 1.0006 - Val accuracy: 0.8387\n",
      "Epoch 11 - Train loss: 0.6407 - Val loss: 0.9484 - Val accuracy: 0.7162\n",
      "Epoch 12 - Train loss: 0.6402 - Val loss: 0.9506 - Val accuracy: 0.8319\n",
      "Epoch 13 - Train loss: 0.6310 - Val loss: 0.8828 - Val accuracy: 0.8482\n",
      "Epoch 14 - Train loss: 0.6232 - Val loss: 0.8841 - Val accuracy: 0.8613\n",
      "Epoch 15 - Train loss: 0.6224 - Val loss: 0.8510 - Val accuracy: 0.8806\n",
      "Epoch 16 - Train loss: 0.6108 - Val loss: 0.8123 - Val accuracy: 0.8853\n",
      "Epoch 17 - Train loss: 0.6059 - Val loss: 0.7751 - Val accuracy: 0.8885\n",
      "Epoch 18 - Train loss: 0.6005 - Val loss: 0.7436 - Val accuracy: 0.9152\n",
      "Epoch 19 - Train loss: 0.5959 - Val loss: 0.7172 - Val accuracy: 0.9063\n",
      "Epoch 20 - Train loss: 0.5916 - Val loss: 0.7177 - Val accuracy: 0.9079\n",
      "Epoch 21 - Train loss: 0.5896 - Val loss: 0.6944 - Val accuracy: 0.9194\n",
      "Epoch 22 - Train loss: 0.5868 - Val loss: 0.6867 - Val accuracy: 0.9246\n",
      "Epoch 23 - Train loss: 0.5861 - Val loss: 0.6887 - Val accuracy: 0.9283\n",
      "Epoch 24 - Train loss: 0.5818 - Val loss: 0.6757 - Val accuracy: 0.9298\n",
      "Epoch 25 - Train loss: 0.5793 - Val loss: 0.6656 - Val accuracy: 0.9429\n",
      "Epoch 26 - Train loss: 0.5779 - Val loss: 0.6673 - Val accuracy: 0.9246\n",
      "Epoch 27 - Train loss: 0.5763 - Val loss: 0.6530 - Val accuracy: 0.9513\n",
      "Epoch 28 - Train loss: 0.5728 - Val loss: 0.6461 - Val accuracy: 0.9461\n",
      "Epoch 29 - Train loss: 0.5720 - Val loss: 0.6436 - Val accuracy: 0.9539\n",
      "Epoch 30 - Train loss: 0.5711 - Val loss: 0.6416 - Val accuracy: 0.9372\n",
      "Epoch 31 - Train loss: 0.5717 - Val loss: 0.6349 - Val accuracy: 0.9513\n",
      "Epoch 32 - Train loss: 0.5682 - Val loss: 0.6387 - Val accuracy: 0.9298\n",
      "Epoch 33 - Train loss: 0.5700 - Val loss: 0.6274 - Val accuracy: 0.9346\n",
      "Epoch 34 - Train loss: 0.5674 - Val loss: 0.6291 - Val accuracy: 0.9524\n",
      "Epoch 35 - Train loss: 0.5681 - Val loss: 0.6247 - Val accuracy: 0.9592\n",
      "Epoch 36 - Train loss: 0.5634 - Val loss: 0.6162 - Val accuracy: 0.9634\n",
      "Epoch 37 - Train loss: 0.5633 - Val loss: 0.6165 - Val accuracy: 0.9529\n",
      "Epoch 38 - Train loss: 0.5626 - Val loss: 0.6160 - Val accuracy: 0.9529\n",
      "Epoch 39 - Train loss: 0.5616 - Val loss: 0.6155 - Val accuracy: 0.9639\n",
      "Epoch 40 - Train loss: 0.5626 - Val loss: 0.6099 - Val accuracy: 0.9602\n",
      "Epoch 41 - Train loss: 0.5620 - Val loss: 0.6096 - Val accuracy: 0.9649\n",
      "Epoch 42 - Train loss: 0.5623 - Val loss: 0.6073 - Val accuracy: 0.9571\n",
      "Epoch 43 - Train loss: 0.5603 - Val loss: 0.6073 - Val accuracy: 0.9660\n",
      "Epoch 44 - Train loss: 0.5598 - Val loss: 0.6041 - Val accuracy: 0.9597\n",
      "Epoch 45 - Train loss: 0.5607 - Val loss: 0.6021 - Val accuracy: 0.9649\n",
      "Epoch 46 - Train loss: 0.5596 - Val loss: 0.6024 - Val accuracy: 0.9628\n",
      "Epoch 47 - Train loss: 0.5596 - Val loss: 0.5997 - Val accuracy: 0.9602\n",
      "Epoch 48 - Train loss: 0.5587 - Val loss: 0.5981 - Val accuracy: 0.9660\n",
      "Epoch 49 - Train loss: 0.5595 - Val loss: 0.5957 - Val accuracy: 0.9649\n",
      "Epoch 50 - Train loss: 0.5580 - Val loss: 0.5970 - Val accuracy: 0.9702\n",
      "Epoch 51 - Train loss: 0.5589 - Val loss: 0.5949 - Val accuracy: 0.9613\n",
      "Epoch 52 - Train loss: 0.5579 - Val loss: 0.5928 - Val accuracy: 0.9749\n",
      "Epoch 53 - Train loss: 0.5564 - Val loss: 0.5931 - Val accuracy: 0.9618\n",
      "Epoch 54 - Train loss: 0.5556 - Val loss: 0.5924 - Val accuracy: 0.9743\n",
      "Epoch 55 - Train loss: 0.5563 - Val loss: 0.5890 - Val accuracy: 0.9770\n",
      "Epoch 56 - Train loss: 0.5565 - Val loss: 0.5897 - Val accuracy: 0.9723\n",
      "Epoch 57 - Train loss: 0.5560 - Val loss: 0.5908 - Val accuracy: 0.9702\n",
      "Epoch 58 - Train loss: 0.5561 - Val loss: 0.5870 - Val accuracy: 0.9733\n",
      "Epoch 59 - Train loss: 0.5566 - Val loss: 0.5859 - Val accuracy: 0.9707\n",
      "Epoch 60 - Train loss: 0.5554 - Val loss: 0.5876 - Val accuracy: 0.9733\n",
      "Epoch 61 - Train loss: 0.5552 - Val loss: 0.5889 - Val accuracy: 0.9723\n",
      "Epoch 62 - Train loss: 0.5542 - Val loss: 0.5864 - Val accuracy: 0.9707\n",
      "Epoch 63 - Train loss: 0.5547 - Val loss: 0.5858 - Val accuracy: 0.9733\n",
      "Epoch 64 - Train loss: 0.5542 - Val loss: 0.5873 - Val accuracy: 0.9717\n",
      "Epoch 65 - Train loss: 0.5552 - Val loss: 0.5843 - Val accuracy: 0.9759\n",
      "Epoch 66 - Train loss: 0.5540 - Val loss: 0.5841 - Val accuracy: 0.9738\n",
      "Epoch 67 - Train loss: 0.5552 - Val loss: 0.5835 - Val accuracy: 0.9749\n",
      "Epoch 68 - Train loss: 0.5544 - Val loss: 0.5833 - Val accuracy: 0.9723\n",
      "Epoch 69 - Train loss: 0.5550 - Val loss: 0.5845 - Val accuracy: 0.9770\n",
      "Epoch 70 - Train loss: 0.5541 - Val loss: 0.5821 - Val accuracy: 0.9738\n",
      "Epoch 71 - Train loss: 0.5539 - Val loss: 0.5807 - Val accuracy: 0.9618\n",
      "Epoch 72 - Train loss: 0.5542 - Val loss: 0.5825 - Val accuracy: 0.9728\n",
      "Epoch 73 - Train loss: 0.5543 - Val loss: 0.5832 - Val accuracy: 0.9770\n",
      "Epoch 74 - Train loss: 0.5543 - Val loss: 0.5819 - Val accuracy: 0.9759\n",
      "Epoch 75 - Train loss: 0.5538 - Val loss: 0.5809 - Val accuracy: 0.9738\n",
      "Epoch 76 - Train loss: 0.5536 - Val loss: 0.5795 - Val accuracy: 0.9723\n",
      "Epoch 77 - Train loss: 0.5533 - Val loss: 0.5805 - Val accuracy: 0.9723\n",
      "Epoch 78 - Train loss: 0.5533 - Val loss: 0.5808 - Val accuracy: 0.9770\n",
      "Epoch 79 - Train loss: 0.5536 - Val loss: 0.5799 - Val accuracy: 0.9592\n",
      "Epoch 80 - Train loss: 0.5537 - Val loss: 0.5795 - Val accuracy: 0.9702\n",
      "Epoch 81 - Train loss: 0.5534 - Val loss: 0.5783 - Val accuracy: 0.9743\n",
      "Epoch 82 - Train loss: 0.5531 - Val loss: 0.5773 - Val accuracy: 0.9770\n",
      "Epoch 83 - Train loss: 0.5530 - Val loss: 0.5785 - Val accuracy: 0.9764\n",
      "Epoch 84 - Train loss: 0.5529 - Val loss: 0.5779 - Val accuracy: 0.9733\n",
      "Epoch 85 - Train loss: 0.5528 - Val loss: 0.5758 - Val accuracy: 0.9775\n",
      "Epoch 86 - Train loss: 0.5531 - Val loss: 0.5760 - Val accuracy: 0.9707\n",
      "Epoch 87 - Train loss: 0.5526 - Val loss: 0.5760 - Val accuracy: 0.9770\n",
      "Epoch 88 - Train loss: 0.5528 - Val loss: 0.5765 - Val accuracy: 0.9749\n",
      "Epoch 89 - Train loss: 0.5531 - Val loss: 0.5777 - Val accuracy: 0.9717\n",
      "Epoch 90 - Train loss: 0.5527 - Val loss: 0.5767 - Val accuracy: 0.9764\n",
      "Epoch 91 - Train loss: 0.5525 - Val loss: 0.5772 - Val accuracy: 0.9806\n",
      "Epoch 92 - Train loss: 0.5526 - Val loss: 0.5756 - Val accuracy: 0.9696\n",
      "Epoch 93 - Train loss: 0.5527 - Val loss: 0.5749 - Val accuracy: 0.9754\n",
      "Epoch 94 - Train loss: 0.5528 - Val loss: 0.5743 - Val accuracy: 0.9670\n",
      "Epoch 95 - Train loss: 0.5526 - Val loss: 0.5765 - Val accuracy: 0.9791\n",
      "Epoch 96 - Train loss: 0.5527 - Val loss: 0.5745 - Val accuracy: 0.9764\n",
      "Epoch 97 - Train loss: 0.5525 - Val loss: 0.5750 - Val accuracy: 0.9764\n",
      "Epoch 98 - Train loss: 0.5533 - Val loss: 0.5750 - Val accuracy: 0.9775\n",
      "Epoch 99 - Train loss: 0.5528 - Val loss: 0.5752 - Val accuracy: 0.9806\n",
      "Epoch 100 - Train loss: 0.5523 - Val loss: 0.5728 - Val accuracy: 0.9764\n",
      "Fold 2/3\n",
      "Epoch 1 - Train loss: 0.9659 - Val loss: 1.2675 - Val accuracy: 0.3494\n",
      "Epoch 2 - Train loss: 1.2245 - Val loss: 1.2020 - Val accuracy: 0.3494\n",
      "Epoch 3 - Train loss: 1.2242 - Val loss: 1.2020 - Val accuracy: 0.3494\n",
      "Epoch 4 - Train loss: 1.1950 - Val loss: 1.2107 - Val accuracy: 0.3536\n",
      "Epoch 5 - Train loss: 0.9548 - Val loss: 1.2513 - Val accuracy: 0.3651\n",
      "Epoch 6 - Train loss: 0.9642 - Val loss: 1.2427 - Val accuracy: 0.3478\n",
      "Epoch 7 - Train loss: 0.9219 - Val loss: 1.1813 - Val accuracy: 0.5217\n",
      "Epoch 8 - Train loss: 0.7514 - Val loss: 1.1699 - Val accuracy: 0.4987\n",
      "Epoch 9 - Train loss: 0.8142 - Val loss: 1.1296 - Val accuracy: 0.7025\n",
      "Epoch 10 - Train loss: 0.6701 - Val loss: 1.1416 - Val accuracy: 0.6517\n",
      "Epoch 11 - Train loss: 0.7040 - Val loss: 1.0820 - Val accuracy: 0.6721\n",
      "Epoch 12 - Train loss: 0.6660 - Val loss: 0.9731 - Val accuracy: 0.6810\n",
      "Epoch 13 - Train loss: 0.6490 - Val loss: 0.9887 - Val accuracy: 0.6511\n",
      "Epoch 14 - Train loss: 0.6465 - Val loss: 0.9731 - Val accuracy: 0.6847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Train loss: 0.6366 - Val loss: 0.9356 - Val accuracy: 0.7690\n",
      "Epoch 16 - Train loss: 0.6173 - Val loss: 0.9032 - Val accuracy: 0.8428\n",
      "Epoch 17 - Train loss: 0.6146 - Val loss: 0.8655 - Val accuracy: 0.8937\n",
      "Epoch 18 - Train loss: 0.6057 - Val loss: 0.8251 - Val accuracy: 0.9005\n",
      "Epoch 19 - Train loss: 0.5996 - Val loss: 0.7737 - Val accuracy: 0.9329\n",
      "Epoch 20 - Train loss: 0.5984 - Val loss: 0.7755 - Val accuracy: 0.9204\n",
      "Epoch 21 - Train loss: 0.5941 - Val loss: 0.7356 - Val accuracy: 0.9340\n",
      "Epoch 22 - Train loss: 0.5914 - Val loss: 0.7253 - Val accuracy: 0.9329\n",
      "Epoch 23 - Train loss: 0.5877 - Val loss: 0.7109 - Val accuracy: 0.9329\n",
      "Epoch 24 - Train loss: 0.5858 - Val loss: 0.6993 - Val accuracy: 0.9350\n",
      "Epoch 25 - Train loss: 0.5840 - Val loss: 0.6872 - Val accuracy: 0.9408\n",
      "Epoch 26 - Train loss: 0.5807 - Val loss: 0.6822 - Val accuracy: 0.9529\n",
      "Epoch 27 - Train loss: 0.5783 - Val loss: 0.6707 - Val accuracy: 0.9529\n",
      "Epoch 28 - Train loss: 0.5763 - Val loss: 0.6628 - Val accuracy: 0.9555\n",
      "Epoch 29 - Train loss: 0.5731 - Val loss: 0.6605 - Val accuracy: 0.9350\n",
      "Epoch 30 - Train loss: 0.5738 - Val loss: 0.6560 - Val accuracy: 0.9550\n",
      "Epoch 31 - Train loss: 0.5706 - Val loss: 0.6532 - Val accuracy: 0.9476\n",
      "Epoch 32 - Train loss: 0.5684 - Val loss: 0.6487 - Val accuracy: 0.9439\n",
      "Epoch 33 - Train loss: 0.5712 - Val loss: 0.6446 - Val accuracy: 0.9481\n",
      "Epoch 34 - Train loss: 0.5681 - Val loss: 0.6381 - Val accuracy: 0.9586\n",
      "Epoch 35 - Train loss: 0.5671 - Val loss: 0.6344 - Val accuracy: 0.9576\n",
      "Epoch 36 - Train loss: 0.5664 - Val loss: 0.6332 - Val accuracy: 0.9644\n",
      "Epoch 37 - Train loss: 0.5639 - Val loss: 0.6324 - Val accuracy: 0.9628\n",
      "Epoch 38 - Train loss: 0.5631 - Val loss: 0.6308 - Val accuracy: 0.9586\n",
      "Epoch 39 - Train loss: 0.5627 - Val loss: 0.6267 - Val accuracy: 0.9550\n",
      "Epoch 40 - Train loss: 0.5615 - Val loss: 0.6197 - Val accuracy: 0.9686\n",
      "Epoch 41 - Train loss: 0.5620 - Val loss: 0.6227 - Val accuracy: 0.9670\n",
      "Epoch 42 - Train loss: 0.5612 - Val loss: 0.6202 - Val accuracy: 0.9586\n",
      "Epoch 43 - Train loss: 0.5597 - Val loss: 0.6174 - Val accuracy: 0.9618\n",
      "Epoch 44 - Train loss: 0.5585 - Val loss: 0.6142 - Val accuracy: 0.9644\n",
      "Epoch 45 - Train loss: 0.5588 - Val loss: 0.6121 - Val accuracy: 0.9618\n",
      "Epoch 46 - Train loss: 0.5590 - Val loss: 0.6155 - Val accuracy: 0.9680\n",
      "Epoch 47 - Train loss: 0.5576 - Val loss: 0.6124 - Val accuracy: 0.9660\n",
      "Epoch 48 - Train loss: 0.5581 - Val loss: 0.6116 - Val accuracy: 0.9701\n",
      "Epoch 49 - Train loss: 0.5578 - Val loss: 0.6078 - Val accuracy: 0.9660\n",
      "Epoch 50 - Train loss: 0.5576 - Val loss: 0.6073 - Val accuracy: 0.9612\n",
      "Epoch 51 - Train loss: 0.5565 - Val loss: 0.6089 - Val accuracy: 0.9686\n",
      "Epoch 52 - Train loss: 0.5558 - Val loss: 0.6084 - Val accuracy: 0.9691\n",
      "Epoch 53 - Train loss: 0.5563 - Val loss: 0.6026 - Val accuracy: 0.9712\n",
      "Epoch 54 - Train loss: 0.5563 - Val loss: 0.6045 - Val accuracy: 0.9728\n",
      "Epoch 55 - Train loss: 0.5564 - Val loss: 0.6002 - Val accuracy: 0.9649\n",
      "Epoch 56 - Train loss: 0.5567 - Val loss: 0.5992 - Val accuracy: 0.9717\n",
      "Epoch 57 - Train loss: 0.5558 - Val loss: 0.5972 - Val accuracy: 0.9665\n",
      "Epoch 58 - Train loss: 0.5556 - Val loss: 0.5970 - Val accuracy: 0.9696\n",
      "Epoch 59 - Train loss: 0.5553 - Val loss: 0.5956 - Val accuracy: 0.9712\n",
      "Epoch 60 - Train loss: 0.5561 - Val loss: 0.5949 - Val accuracy: 0.9722\n",
      "Epoch 61 - Train loss: 0.5549 - Val loss: 0.5962 - Val accuracy: 0.9707\n",
      "Epoch 62 - Train loss: 0.5551 - Val loss: 0.5948 - Val accuracy: 0.9607\n",
      "Epoch 63 - Train loss: 0.5545 - Val loss: 0.5954 - Val accuracy: 0.9707\n",
      "Epoch 64 - Train loss: 0.5538 - Val loss: 0.5944 - Val accuracy: 0.9733\n",
      "Epoch 65 - Train loss: 0.5543 - Val loss: 0.5920 - Val accuracy: 0.9707\n",
      "Epoch 66 - Train loss: 0.5541 - Val loss: 0.5930 - Val accuracy: 0.9717\n",
      "Epoch 67 - Train loss: 0.5533 - Val loss: 0.5943 - Val accuracy: 0.9754\n",
      "Epoch 68 - Train loss: 0.5540 - Val loss: 0.5893 - Val accuracy: 0.9712\n",
      "Epoch 69 - Train loss: 0.5544 - Val loss: 0.5912 - Val accuracy: 0.9738\n",
      "Epoch 70 - Train loss: 0.5539 - Val loss: 0.5879 - Val accuracy: 0.9738\n",
      "Epoch 71 - Train loss: 0.5534 - Val loss: 0.5894 - Val accuracy: 0.9670\n",
      "Epoch 72 - Train loss: 0.5539 - Val loss: 0.5868 - Val accuracy: 0.9707\n",
      "Epoch 73 - Train loss: 0.5539 - Val loss: 0.5873 - Val accuracy: 0.9686\n",
      "Epoch 74 - Train loss: 0.5540 - Val loss: 0.5879 - Val accuracy: 0.9707\n",
      "Epoch 75 - Train loss: 0.5532 - Val loss: 0.5875 - Val accuracy: 0.9707\n",
      "Epoch 76 - Train loss: 0.5535 - Val loss: 0.5848 - Val accuracy: 0.9733\n",
      "Epoch 77 - Train loss: 0.5530 - Val loss: 0.5846 - Val accuracy: 0.9780\n",
      "Epoch 78 - Train loss: 0.5536 - Val loss: 0.5847 - Val accuracy: 0.9743\n",
      "Epoch 79 - Train loss: 0.5534 - Val loss: 0.5861 - Val accuracy: 0.9691\n",
      "Epoch 80 - Train loss: 0.5533 - Val loss: 0.5845 - Val accuracy: 0.9754\n",
      "Epoch 81 - Train loss: 0.5530 - Val loss: 0.5824 - Val accuracy: 0.9785\n",
      "Epoch 82 - Train loss: 0.5532 - Val loss: 0.5809 - Val accuracy: 0.9722\n",
      "Epoch 83 - Train loss: 0.5526 - Val loss: 0.5798 - Val accuracy: 0.9754\n",
      "Epoch 84 - Train loss: 0.5530 - Val loss: 0.5783 - Val accuracy: 0.9738\n",
      "Epoch 85 - Train loss: 0.5531 - Val loss: 0.5795 - Val accuracy: 0.9759\n",
      "Epoch 86 - Train loss: 0.5526 - Val loss: 0.5792 - Val accuracy: 0.9743\n",
      "Epoch 87 - Train loss: 0.5525 - Val loss: 0.5775 - Val accuracy: 0.9754\n",
      "Epoch 88 - Train loss: 0.5524 - Val loss: 0.5806 - Val accuracy: 0.9764\n",
      "Epoch 89 - Train loss: 0.5527 - Val loss: 0.5799 - Val accuracy: 0.9712\n",
      "Epoch 90 - Train loss: 0.5529 - Val loss: 0.5790 - Val accuracy: 0.9738\n",
      "Epoch 91 - Train loss: 0.5525 - Val loss: 0.5802 - Val accuracy: 0.9770\n",
      "Epoch 92 - Train loss: 0.5524 - Val loss: 0.5782 - Val accuracy: 0.9759\n",
      "Epoch 93 - Train loss: 0.5525 - Val loss: 0.5760 - Val accuracy: 0.9759\n",
      "Epoch 94 - Train loss: 0.5528 - Val loss: 0.5793 - Val accuracy: 0.9764\n",
      "Epoch 95 - Train loss: 0.5522 - Val loss: 0.5767 - Val accuracy: 0.9770\n",
      "Epoch 96 - Train loss: 0.5525 - Val loss: 0.5769 - Val accuracy: 0.9754\n",
      "Epoch 97 - Train loss: 0.5525 - Val loss: 0.5769 - Val accuracy: 0.9785\n",
      "Epoch 98 - Train loss: 0.5524 - Val loss: 0.5764 - Val accuracy: 0.9790\n",
      "Epoch 99 - Train loss: 0.5523 - Val loss: 0.5768 - Val accuracy: 0.9670\n",
      "Epoch 100 - Train loss: 0.5531 - Val loss: 0.5762 - Val accuracy: 0.9780\n",
      "Fold 3/3\n",
      "Epoch 1 - Train loss: 0.9769 - Val loss: 1.3047 - Val accuracy: 0.3232\n",
      "Epoch 2 - Train loss: 1.2086 - Val loss: 1.2092 - Val accuracy: 0.4343\n",
      "Epoch 3 - Train loss: 0.9816 - Val loss: 1.2192 - Val accuracy: 0.4374\n",
      "Epoch 4 - Train loss: 0.9607 - Val loss: 1.2133 - Val accuracy: 0.4620\n",
      "Epoch 5 - Train loss: 0.8313 - Val loss: 1.2209 - Val accuracy: 0.5752\n",
      "Epoch 6 - Train loss: 0.7313 - Val loss: 1.1467 - Val accuracy: 0.5537\n",
      "Epoch 7 - Train loss: 0.7143 - Val loss: 1.0668 - Val accuracy: 0.5458\n",
      "Epoch 8 - Train loss: 0.7095 - Val loss: 1.0757 - Val accuracy: 0.6553\n",
      "Epoch 9 - Train loss: 0.6637 - Val loss: 1.0370 - Val accuracy: 0.7638\n",
      "Epoch 10 - Train loss: 0.6641 - Val loss: 1.0213 - Val accuracy: 0.6506\n",
      "Epoch 11 - Train loss: 0.6562 - Val loss: 1.0016 - Val accuracy: 0.7381\n",
      "Epoch 12 - Train loss: 0.6571 - Val loss: 0.9375 - Val accuracy: 0.7606\n",
      "Epoch 13 - Train loss: 0.6319 - Val loss: 0.9247 - Val accuracy: 0.8607\n",
      "Epoch 14 - Train loss: 0.6246 - Val loss: 0.9012 - Val accuracy: 0.8800\n",
      "Epoch 15 - Train loss: 0.6203 - Val loss: 0.8458 - Val accuracy: 0.8706\n",
      "Epoch 16 - Train loss: 0.6120 - Val loss: 0.8160 - Val accuracy: 0.8764\n",
      "Epoch 17 - Train loss: 0.6095 - Val loss: 0.7775 - Val accuracy: 0.9167\n",
      "Epoch 18 - Train loss: 0.6029 - Val loss: 0.7498 - Val accuracy: 0.9335\n",
      "Epoch 19 - Train loss: 0.5969 - Val loss: 0.7271 - Val accuracy: 0.9366\n",
      "Epoch 20 - Train loss: 0.5926 - Val loss: 0.7108 - Val accuracy: 0.9293\n",
      "Epoch 21 - Train loss: 0.5904 - Val loss: 0.7055 - Val accuracy: 0.9340\n",
      "Epoch 22 - Train loss: 0.5882 - Val loss: 0.6917 - Val accuracy: 0.9324\n",
      "Epoch 23 - Train loss: 0.5848 - Val loss: 0.6828 - Val accuracy: 0.9439\n",
      "Epoch 24 - Train loss: 0.5823 - Val loss: 0.6742 - Val accuracy: 0.9230\n",
      "Epoch 25 - Train loss: 0.5811 - Val loss: 0.6681 - Val accuracy: 0.9282\n",
      "Epoch 26 - Train loss: 0.5789 - Val loss: 0.6585 - Val accuracy: 0.9277\n",
      "Epoch 27 - Train loss: 0.5765 - Val loss: 0.6559 - Val accuracy: 0.9424\n",
      "Epoch 28 - Train loss: 0.5759 - Val loss: 0.6515 - Val accuracy: 0.9329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 - Train loss: 0.5748 - Val loss: 0.6493 - Val accuracy: 0.9361\n",
      "Epoch 30 - Train loss: 0.5731 - Val loss: 0.6426 - Val accuracy: 0.9324\n",
      "Epoch 31 - Train loss: 0.5725 - Val loss: 0.6401 - Val accuracy: 0.9476\n",
      "Epoch 32 - Train loss: 0.5702 - Val loss: 0.6375 - Val accuracy: 0.9481\n",
      "Epoch 33 - Train loss: 0.5688 - Val loss: 0.6342 - Val accuracy: 0.9513\n",
      "Epoch 34 - Train loss: 0.5671 - Val loss: 0.6306 - Val accuracy: 0.9560\n",
      "Epoch 35 - Train loss: 0.5661 - Val loss: 0.6290 - Val accuracy: 0.9597\n",
      "Epoch 36 - Train loss: 0.5655 - Val loss: 0.6233 - Val accuracy: 0.9471\n",
      "Epoch 37 - Train loss: 0.5637 - Val loss: 0.6180 - Val accuracy: 0.9597\n",
      "Epoch 38 - Train loss: 0.5651 - Val loss: 0.6229 - Val accuracy: 0.9471\n",
      "Epoch 39 - Train loss: 0.5642 - Val loss: 0.6142 - Val accuracy: 0.9696\n",
      "Epoch 40 - Train loss: 0.5615 - Val loss: 0.6163 - Val accuracy: 0.9665\n",
      "Epoch 41 - Train loss: 0.5625 - Val loss: 0.6140 - Val accuracy: 0.9649\n",
      "Epoch 42 - Train loss: 0.5608 - Val loss: 0.6144 - Val accuracy: 0.9628\n",
      "Epoch 43 - Train loss: 0.5602 - Val loss: 0.6090 - Val accuracy: 0.9612\n",
      "Epoch 44 - Train loss: 0.5601 - Val loss: 0.6052 - Val accuracy: 0.9623\n",
      "Epoch 45 - Train loss: 0.5609 - Val loss: 0.6090 - Val accuracy: 0.9670\n",
      "Epoch 46 - Train loss: 0.5593 - Val loss: 0.6077 - Val accuracy: 0.9597\n",
      "Epoch 47 - Train loss: 0.5596 - Val loss: 0.6059 - Val accuracy: 0.9654\n",
      "Epoch 48 - Train loss: 0.5585 - Val loss: 0.6038 - Val accuracy: 0.9660\n",
      "Epoch 49 - Train loss: 0.5577 - Val loss: 0.6014 - Val accuracy: 0.9701\n",
      "Epoch 50 - Train loss: 0.5573 - Val loss: 0.5998 - Val accuracy: 0.9754\n",
      "Epoch 51 - Train loss: 0.5579 - Val loss: 0.5989 - Val accuracy: 0.9728\n",
      "Epoch 52 - Train loss: 0.5569 - Val loss: 0.5994 - Val accuracy: 0.9743\n",
      "Epoch 53 - Train loss: 0.5577 - Val loss: 0.5965 - Val accuracy: 0.9691\n",
      "Epoch 54 - Train loss: 0.5562 - Val loss: 0.5961 - Val accuracy: 0.9749\n",
      "Epoch 55 - Train loss: 0.5567 - Val loss: 0.5914 - Val accuracy: 0.9628\n",
      "Epoch 56 - Train loss: 0.5560 - Val loss: 0.5914 - Val accuracy: 0.9701\n",
      "Epoch 57 - Train loss: 0.5558 - Val loss: 0.5903 - Val accuracy: 0.9728\n",
      "Epoch 58 - Train loss: 0.5554 - Val loss: 0.5891 - Val accuracy: 0.9733\n",
      "Epoch 59 - Train loss: 0.5558 - Val loss: 0.5882 - Val accuracy: 0.9728\n",
      "Epoch 60 - Train loss: 0.5563 - Val loss: 0.5861 - Val accuracy: 0.9780\n",
      "Epoch 61 - Train loss: 0.5552 - Val loss: 0.5863 - Val accuracy: 0.9780\n",
      "Epoch 62 - Train loss: 0.5552 - Val loss: 0.5838 - Val accuracy: 0.9775\n",
      "Epoch 63 - Train loss: 0.5550 - Val loss: 0.5869 - Val accuracy: 0.9759\n",
      "Epoch 64 - Train loss: 0.5549 - Val loss: 0.5836 - Val accuracy: 0.9770\n",
      "Epoch 65 - Train loss: 0.5543 - Val loss: 0.5852 - Val accuracy: 0.9770\n",
      "Epoch 66 - Train loss: 0.5553 - Val loss: 0.5836 - Val accuracy: 0.9602\n",
      "Epoch 67 - Train loss: 0.5551 - Val loss: 0.5838 - Val accuracy: 0.9770\n",
      "Epoch 68 - Train loss: 0.5542 - Val loss: 0.5826 - Val accuracy: 0.9790\n",
      "Epoch 69 - Train loss: 0.5541 - Val loss: 0.5802 - Val accuracy: 0.9790\n",
      "Epoch 70 - Train loss: 0.5548 - Val loss: 0.5807 - Val accuracy: 0.9796\n",
      "Epoch 71 - Train loss: 0.5541 - Val loss: 0.5797 - Val accuracy: 0.9801\n",
      "Epoch 72 - Train loss: 0.5545 - Val loss: 0.5785 - Val accuracy: 0.9785\n",
      "Epoch 73 - Train loss: 0.5539 - Val loss: 0.5815 - Val accuracy: 0.9801\n",
      "Epoch 74 - Train loss: 0.5543 - Val loss: 0.5794 - Val accuracy: 0.9764\n",
      "Epoch 75 - Train loss: 0.5533 - Val loss: 0.5796 - Val accuracy: 0.9754\n",
      "Epoch 76 - Train loss: 0.5538 - Val loss: 0.5791 - Val accuracy: 0.9743\n",
      "Epoch 77 - Train loss: 0.5539 - Val loss: 0.5797 - Val accuracy: 0.9743\n",
      "Epoch 78 - Train loss: 0.5539 - Val loss: 0.5771 - Val accuracy: 0.9728\n",
      "Epoch 79 - Train loss: 0.5535 - Val loss: 0.5768 - Val accuracy: 0.9754\n",
      "Epoch 80 - Train loss: 0.5538 - Val loss: 0.5775 - Val accuracy: 0.9838\n",
      "Epoch 81 - Train loss: 0.5537 - Val loss: 0.5758 - Val accuracy: 0.9822\n",
      "Epoch 82 - Train loss: 0.5536 - Val loss: 0.5774 - Val accuracy: 0.9817\n",
      "Epoch 83 - Train loss: 0.5539 - Val loss: 0.5763 - Val accuracy: 0.9811\n",
      "Epoch 84 - Train loss: 0.5537 - Val loss: 0.5750 - Val accuracy: 0.9796\n",
      "Epoch 85 - Train loss: 0.5533 - Val loss: 0.5738 - Val accuracy: 0.9749\n",
      "Epoch 86 - Train loss: 0.5534 - Val loss: 0.5746 - Val accuracy: 0.9796\n",
      "Epoch 87 - Train loss: 0.5534 - Val loss: 0.5743 - Val accuracy: 0.9754\n",
      "Epoch 88 - Train loss: 0.5533 - Val loss: 0.5755 - Val accuracy: 0.9822\n",
      "Epoch 89 - Train loss: 0.5532 - Val loss: 0.5713 - Val accuracy: 0.9832\n",
      "Epoch 90 - Train loss: 0.5532 - Val loss: 0.5737 - Val accuracy: 0.9801\n",
      "Epoch 91 - Train loss: 0.5534 - Val loss: 0.5732 - Val accuracy: 0.9811\n",
      "Epoch 92 - Train loss: 0.5532 - Val loss: 0.5740 - Val accuracy: 0.9770\n",
      "Epoch 93 - Train loss: 0.5533 - Val loss: 0.5749 - Val accuracy: 0.9832\n",
      "Epoch 94 - Train loss: 0.5531 - Val loss: 0.5740 - Val accuracy: 0.9785\n",
      "Epoch 95 - Train loss: 0.5531 - Val loss: 0.5729 - Val accuracy: 0.9749\n",
      "Epoch 96 - Train loss: 0.5530 - Val loss: 0.5745 - Val accuracy: 0.9822\n",
      "Epoch 97 - Train loss: 0.5532 - Val loss: 0.5722 - Val accuracy: 0.9838\n",
      "Epoch 98 - Train loss: 0.5535 - Val loss: 0.5709 - Val accuracy: 0.9728\n",
      "Epoch 99 - Train loss: 0.5530 - Val loss: 0.5713 - Val accuracy: 0.9864\n",
      "Epoch 100 - Train loss: 0.5533 - Val loss: 0.5713 - Val accuracy: 0.9817\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 44>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Print overall validation accuracy\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverall validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(val_accuracies)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3429\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3430\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3433\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\numpy\\core\\_methods.py:164\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 164\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\torch\\_tensor.py:956\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Initialize lists to store training and validation losses and accuracies\n",
    "\n",
    "\n",
    "# Train and validate for each fold\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(train_dataset)):\n",
    "    print(f'Fold {fold + 1}/{k}')\n",
    "    \n",
    "    # Create subset datasets and dataloaders for this fold\n",
    "    train_subset = Subset(train_dataset, train_indices)\n",
    "    val_subset = Subset(train_dataset, val_indices)\n",
    "    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n",
    "    # Define model,\n",
    "    model = SmallResNet9()\n",
    "    model.to(device)\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), learning_rate)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Train and validate for this fold\n",
    "    for epoch in range(number_of_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer)\n",
    "#         val_loss = evaluate(model, val_loader)\n",
    "        val_loss = train(model,val_loader,criterion,optimizer)\n",
    "        val_accuracy = evaluate(model, val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        print(f'Epoch {epoch + 1} - Train loss: {train_loss:.4f} - Val loss: {val_loss:.4f} - Val accuracy: {val_accuracy:.4f}')\n",
    "    \n",
    "    torch.save(model, f'fold{fold}.pth')\n",
    "    \n",
    "# Print overall validation accuracy\n",
    "# print(f'Overall validation accuracy: {np.mean(val_accuracies):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49285d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "torch.save(model, './saved_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71cfac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the losses\n",
    "def plot_losses():\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c1a0de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef22f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ImageFolder(data_dir+'/test', valid_tfms)\n",
    "test_dl = DataLoader(test_ds, batch_size, num_workers=3, pin_memory=True)\n",
    "test_dl = DeviceDataLoader(test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7c9d1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmallResNet9(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the model\n",
    "test_model = SmallResNet9()\n",
    "PATH = 'fold1.pth'\n",
    "test_model = torch.load(PATH, map_location = device)\n",
    "test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec876665",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for data in test_dl:\n",
    "#         images, labels = data\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "#         outputs = test_model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print('Accuracy of the ResNet9 model on the %d test images: %d %%' % (total, 100 * correct / total))\n",
    "\n",
    "def evaluate_test_data(model, val_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = test_model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.append(labels)\n",
    "            all_preds.append(preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    f1 = F1Score(task=\"multiclass\", num_classes=num_of_classes,average='weighted').to(device)\n",
    "    a = f1(all_preds, all_labels)\n",
    "    acc = Accuracy(task=\"multiclass\", num_classes=num_of_classes).to(device)\n",
    "    b = acc(all_preds, all_labels)\n",
    "    print('F1 Score:- ', a)\n",
    "    print('Accuracy:-', b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2048ecf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:-  tensor(0.6263, device='cuda:0')\n",
      "Accuracy:- tensor(0.6184, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "evaluate_test_data(test_model,test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc4c5ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for data in test_dl:\n",
    "#         images, labels = data\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "#         outputs = test_model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print('Accuracy of the ResNet9 model on the %d test images: %d %%' % (total, 100 * correct / total))\n",
    "\n",
    "def evaluate_test_data_numpy(model, val_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = test_model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    f1score = f1_score(all_labels, all_preds, average='weighted')\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print('F1 Score:- ', f1score)\n",
    "    print('Accuracy:- ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a87ef2f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_test_data_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36mevaluate_test_data_numpy\u001b[1;34m(model, val_loader)\u001b[0m\n\u001b[0;32m     27\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(all_labels)\n\u001b[0;32m     28\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(all_preds)\n\u001b[1;32m---> 29\u001b[0m f1score \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m(all_labels, all_preds, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(all_labels, all_preds)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1 Score:- \u001b[39m\u001b[38;5;124m'\u001b[39m, f1score)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f1_score' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_test_data_numpy(test_model,test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3c356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([0, 1, 2, 0, 1, 2])\n",
    "preds = torch.tensor([0, 2, 1, 0, 0, 1])\n",
    "\n",
    "f1 = F1Score(task=\"multiclass\", num_classes=3)\n",
    "a = f1(preds, target)\n",
    "\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=3)\n",
    "b = accuracy(preds, target)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358fbc90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
