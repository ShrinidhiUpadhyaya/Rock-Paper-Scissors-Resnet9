{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7aec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transform\n",
    "import torchmetrics\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as matplot\n",
    "\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "from torch.utils.data import DataLoader, Subset, random_split, ConcatDataset\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc45b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0db4a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name='rock-paper-scissors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e726e551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paper', 'rock', 'scissors']\n",
      "['paper', 'rock', 'scissors']\n"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "data_dir = './dataset'\n",
    "print(os.listdir(data_dir))\n",
    "\n",
    "# Classes\n",
    "classes = os.listdir(data_dir)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb730e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "train_tranform = transform.Compose([\n",
    "                         transform.Resize((32,32)), \n",
    "                         transform.RandomHorizontalFlip(), \n",
    "                         transform.ToTensor(), \n",
    "                         transform.Normalize(*stats,inplace=True)])\n",
    "\n",
    "valid_transform = transform.Compose([transform.Resize((32,32)),transform.ToTensor(), transform.Normalize(*stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa4e4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_paper_scissors_data = ImageFolder(data_dir, train_tranform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee047326",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.85 * len(rock_paper_scissors_data))\n",
    "val_size = len(rock_paper_scissors_data) - train_size\n",
    "train_dataset, val_dataset = random_split(rock_paper_scissors_data, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88597fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_of_classes = len(classes)\n",
    "num_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8f5c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_val_dataset = ImageFolder(\"./professor-dataset/validation\", valid_transform)\n",
    "complete_val_dataset = ConcatDataset([val_dataset,custom_val_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94c6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Just the custom validation dataloader\n",
    "# custom_validation_dataloader = DataLoader(custom_val_dataset, batch_size=batch_size, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "facf2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageFolder(\"./professor-dataset/test\", valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4df173b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "val_dataloader = DataLoader(complete_val_dataset, batch_size=batch_size, num_workers=3, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39071f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08643155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show images\n",
    "def show_images(dataloader):\n",
    "    for images, labels in dataloader:\n",
    "        fig, ax = matplot.subplots(figsize=(12, 12))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcc30f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79728bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "740b583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Dataloader on the device('Cuda' if available)\n",
    "train_dataloader = DeviceDataLoader(train_dataloader, device)\n",
    "# val_dataloader = DeviceDataLoader(val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836bb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = conv_block(3, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True)\n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(512, num_classes))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f5d81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "number_of_epochs = 25\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a3304b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-1 Score\n",
    "def get_f1score(preds, labels):\n",
    "    f1_score = F1Score(task=\"multiclass\", num_classes=num_of_classes, average='weighted')\n",
    "    return f1_score(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80ce2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def get_accuracy(preds, labels):\n",
    "    accuracy = Accuracy(task=\"multiclass\", num_classes=num_of_classes).to(device)\n",
    "    return accuracy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a37e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edc96273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    return all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without K-fold cross-validation\n",
    "    \n",
    "model = ResNet9()\n",
    "model.to(device)\n",
    "    \n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "    \n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "    \n",
    "# Train and validate for this fold\n",
    "for epoch in range(number_of_epochs):\n",
    "    train_loss = train(model, train_dataloader, criterion, optimizer)\n",
    "    val_loss = train(model,val_dataloader,criterion,optimizer)\n",
    "        \n",
    "    # Loss\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "        \n",
    "    preds, labels = evaluate(model, train_dataloader)\n",
    "    train_accuracy = get_accuracy(preds, labels)\n",
    "\n",
    "    preds, labels = evaluate(model, val_dataloader)\n",
    "    val_accuracy = get_accuracy(preds, labels)\n",
    "\n",
    "    # Accuracies\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "        \n",
    "    print(f'Epoch {epoch + 1} - Train loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Val loss: {val_loss:.4f} - Val accuracy: {val_accuracy:.4f}')\n",
    "    \n",
    "# Saving the Current Fold Model\n",
    "torch.save(model, f'withoutKFold.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1926f8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/3\n",
      "Epoch 1 - Train loss: 0.7844 - Train Accuracy: 0.8184 - Val loss: 0.5750 - Val accuracy: 0.7939\n",
      "Epoch 2 - Train loss: 0.3553 - Train Accuracy: 0.8798 - Val loss: 0.3655 - Val accuracy: 0.8500\n",
      "Epoch 3 - Train loss: 0.2366 - Train Accuracy: 0.8970 - Val loss: 0.2342 - Val accuracy: 0.8853\n",
      "Epoch 4 - Train loss: 0.2110 - Train Accuracy: 0.9560 - Val loss: 0.1926 - Val accuracy: 0.9190\n",
      "Epoch 5 - Train loss: 0.1303 - Train Accuracy: 0.9200 - Val loss: 0.1561 - Val accuracy: 0.8893\n",
      "Epoch 6 - Train loss: 0.1051 - Train Accuracy: 0.9802 - Val loss: 0.1327 - Val accuracy: 0.9455\n",
      "Epoch 7 - Train loss: 0.0842 - Train Accuracy: 0.9287 - Val loss: 0.1170 - Val accuracy: 0.8893\n",
      "Epoch 8 - Train loss: 0.0578 - Train Accuracy: 0.9908 - Val loss: 0.1004 - Val accuracy: 0.9599\n",
      "Epoch 9 - Train loss: 0.0458 - Train Accuracy: 0.9929 - Val loss: 0.0824 - Val accuracy: 0.9631\n",
      "Epoch 10 - Train loss: 0.0333 - Train Accuracy: 0.9929 - Val loss: 0.0814 - Val accuracy: 0.9695\n",
      "Epoch 11 - Train loss: 0.0266 - Train Accuracy: 0.9974 - Val loss: 0.0696 - Val accuracy: 0.9663\n",
      "Epoch 12 - Train loss: 0.0235 - Train Accuracy: 0.9932 - Val loss: 0.0486 - Val accuracy: 0.9671\n",
      "Epoch 13 - Train loss: 0.0195 - Train Accuracy: 0.9988 - Val loss: 0.0317 - Val accuracy: 0.9800\n",
      "Epoch 14 - Train loss: 0.0134 - Train Accuracy: 1.0000 - Val loss: 0.0217 - Val accuracy: 0.9743\n",
      "Epoch 15 - Train loss: 0.0070 - Train Accuracy: 1.0000 - Val loss: 0.0250 - Val accuracy: 0.9808\n",
      "Epoch 16 - Train loss: 0.0084 - Train Accuracy: 1.0000 - Val loss: 0.0206 - Val accuracy: 0.9711\n",
      "Epoch 17 - Train loss: 0.0054 - Train Accuracy: 1.0000 - Val loss: 0.0132 - Val accuracy: 0.9775\n",
      "Epoch 18 - Train loss: 0.0039 - Train Accuracy: 1.0000 - Val loss: 0.0068 - Val accuracy: 0.9759\n",
      "Epoch 19 - Train loss: 0.0017 - Train Accuracy: 1.0000 - Val loss: 0.0038 - Val accuracy: 0.9824\n",
      "Epoch 20 - Train loss: 0.0014 - Train Accuracy: 1.0000 - Val loss: 0.0021 - Val accuracy: 0.9800\n",
      "Epoch 21 - Train loss: 0.0008 - Train Accuracy: 1.0000 - Val loss: 0.0017 - Val accuracy: 0.9783\n",
      "Epoch 22 - Train loss: 0.0010 - Train Accuracy: 1.0000 - Val loss: 0.0015 - Val accuracy: 0.9816\n",
      "Epoch 23 - Train loss: 0.0005 - Train Accuracy: 1.0000 - Val loss: 0.0012 - Val accuracy: 0.9808\n",
      "Epoch 24 - Train loss: 0.0005 - Train Accuracy: 1.0000 - Val loss: 0.0011 - Val accuracy: 0.9808\n",
      "Epoch 25 - Train loss: 0.0004 - Train Accuracy: 1.0000 - Val loss: 0.0010 - Val accuracy: 0.9816\n",
      "Fold 2/3\n",
      "Epoch 1 - Train loss: 0.7997 - Train Accuracy: 0.7764 - Val loss: 0.5668 - Val accuracy: 0.7723\n",
      "Epoch 2 - Train loss: 0.3283 - Train Accuracy: 0.8335 - Val loss: 0.3851 - Val accuracy: 0.8196\n",
      "Epoch 3 - Train loss: 0.2227 - Train Accuracy: 0.8751 - Val loss: 0.2424 - Val accuracy: 0.8549\n",
      "Epoch 4 - Train loss: 0.1593 - Train Accuracy: 0.8836 - Val loss: 0.1798 - Val accuracy: 0.8420\n",
      "Epoch 5 - Train loss: 0.1351 - Train Accuracy: 0.9802 - Val loss: 0.1667 - Val accuracy: 0.9503\n",
      "Epoch 6 - Train loss: 0.0631 - Train Accuracy: 0.9824 - Val loss: 0.1396 - Val accuracy: 0.9543\n",
      "Epoch 7 - Train loss: 0.0845 - Train Accuracy: 0.9845 - Val loss: 0.1534 - Val accuracy: 0.9543\n",
      "Epoch 8 - Train loss: 0.0563 - Train Accuracy: 0.9812 - Val loss: 0.1207 - Val accuracy: 0.9455\n",
      "Epoch 9 - Train loss: 0.0454 - Train Accuracy: 0.9958 - Val loss: 0.0875 - Val accuracy: 0.9695\n",
      "Epoch 10 - Train loss: 0.0304 - Train Accuracy: 0.9976 - Val loss: 0.0729 - Val accuracy: 0.9751\n",
      "Epoch 11 - Train loss: 0.0221 - Train Accuracy: 0.9941 - Val loss: 0.0681 - Val accuracy: 0.9719\n",
      "Epoch 12 - Train loss: 0.0215 - Train Accuracy: 0.9974 - Val loss: 0.0394 - Val accuracy: 0.9711\n",
      "Epoch 13 - Train loss: 0.0146 - Train Accuracy: 0.9991 - Val loss: 0.0399 - Val accuracy: 0.9679\n",
      "Epoch 14 - Train loss: 0.0133 - Train Accuracy: 0.9995 - Val loss: 0.0316 - Val accuracy: 0.9647\n",
      "Epoch 15 - Train loss: 0.0128 - Train Accuracy: 0.9998 - Val loss: 0.0193 - Val accuracy: 0.9783\n",
      "Epoch 16 - Train loss: 0.0070 - Train Accuracy: 1.0000 - Val loss: 0.0100 - Val accuracy: 0.9816\n",
      "Epoch 17 - Train loss: 0.0028 - Train Accuracy: 1.0000 - Val loss: 0.0075 - Val accuracy: 0.9775\n",
      "Epoch 18 - Train loss: 0.0020 - Train Accuracy: 1.0000 - Val loss: 0.0048 - Val accuracy: 0.9808\n",
      "Epoch 19 - Train loss: 0.0016 - Train Accuracy: 1.0000 - Val loss: 0.0036 - Val accuracy: 0.9824\n",
      "Epoch 20 - Train loss: 0.0012 - Train Accuracy: 1.0000 - Val loss: 0.0020 - Val accuracy: 0.9800\n",
      "Epoch 21 - Train loss: 0.0010 - Train Accuracy: 1.0000 - Val loss: 0.0015 - Val accuracy: 0.9808\n",
      "Epoch 22 - Train loss: 0.0007 - Train Accuracy: 1.0000 - Val loss: 0.0013 - Val accuracy: 0.9783\n",
      "Epoch 23 - Train loss: 0.0009 - Train Accuracy: 1.0000 - Val loss: 0.0013 - Val accuracy: 0.9808\n",
      "Epoch 24 - Train loss: 0.0005 - Train Accuracy: 1.0000 - Val loss: 0.0011 - Val accuracy: 0.9791\n",
      "Epoch 25 - Train loss: 0.0005 - Train Accuracy: 1.0000 - Val loss: 0.0010 - Val accuracy: 0.9808\n",
      "Fold 3/3\n",
      "Epoch 1 - Train loss: 0.8471 - Train Accuracy: 0.7656 - Val loss: 0.5849 - Val accuracy: 0.7306\n",
      "Epoch 2 - Train loss: 0.3399 - Train Accuracy: 0.8396 - Val loss: 0.3477 - Val accuracy: 0.8284\n",
      "Epoch 3 - Train loss: 0.2472 - Train Accuracy: 0.8895 - Val loss: 0.2551 - Val accuracy: 0.8653\n",
      "Epoch 4 - Train loss: 0.1444 - Train Accuracy: 0.9643 - Val loss: 0.1678 - Val accuracy: 0.9487\n",
      "Epoch 5 - Train loss: 0.1137 - Train Accuracy: 0.9680 - Val loss: 0.1702 - Val accuracy: 0.9471\n",
      "Epoch 6 - Train loss: 0.0825 - Train Accuracy: 0.9824 - Val loss: 0.1206 - Val accuracy: 0.9495\n",
      "Epoch 7 - Train loss: 0.0860 - Train Accuracy: 0.9859 - Val loss: 0.1451 - Val accuracy: 0.9567\n",
      "Epoch 8 - Train loss: 0.0473 - Train Accuracy: 0.9958 - Val loss: 0.0971 - Val accuracy: 0.9751\n",
      "Epoch 9 - Train loss: 0.0368 - Train Accuracy: 0.9979 - Val loss: 0.0916 - Val accuracy: 0.9655\n",
      "Epoch 10 - Train loss: 0.0283 - Train Accuracy: 0.9988 - Val loss: 0.0643 - Val accuracy: 0.9679\n",
      "Epoch 11 - Train loss: 0.0240 - Train Accuracy: 0.9995 - Val loss: 0.0498 - Val accuracy: 0.9735\n",
      "Epoch 12 - Train loss: 0.0150 - Train Accuracy: 0.9984 - Val loss: 0.0297 - Val accuracy: 0.9759\n",
      "Epoch 13 - Train loss: 0.0118 - Train Accuracy: 0.9998 - Val loss: 0.0300 - Val accuracy: 0.9743\n",
      "Epoch 14 - Train loss: 0.0106 - Train Accuracy: 0.9995 - Val loss: 0.0252 - Val accuracy: 0.9767\n",
      "Epoch 15 - Train loss: 0.0097 - Train Accuracy: 1.0000 - Val loss: 0.0214 - Val accuracy: 0.9727\n",
      "Epoch 16 - Train loss: 0.0057 - Train Accuracy: 1.0000 - Val loss: 0.0151 - Val accuracy: 0.9775\n",
      "Epoch 17 - Train loss: 0.0046 - Train Accuracy: 1.0000 - Val loss: 0.0081 - Val accuracy: 0.9832\n",
      "Epoch 18 - Train loss: 0.0037 - Train Accuracy: 1.0000 - Val loss: 0.0052 - Val accuracy: 0.9872\n",
      "Epoch 19 - Train loss: 0.0022 - Train Accuracy: 1.0000 - Val loss: 0.0027 - Val accuracy: 0.9864\n",
      "Epoch 20 - Train loss: 0.0014 - Train Accuracy: 1.0000 - Val loss: 0.0020 - Val accuracy: 0.9864\n",
      "Epoch 21 - Train loss: 0.0008 - Train Accuracy: 1.0000 - Val loss: 0.0016 - Val accuracy: 0.9880\n",
      "Epoch 22 - Train loss: 0.0007 - Train Accuracy: 1.0000 - Val loss: 0.0014 - Val accuracy: 0.9888\n",
      "Epoch 23 - Train loss: 0.0010 - Train Accuracy: 1.0000 - Val loss: 0.0013 - Val accuracy: 0.9888\n",
      "Epoch 24 - Train loss: 0.0006 - Train Accuracy: 1.0000 - Val loss: 0.0012 - Val accuracy: 0.9880\n",
      "Epoch 25 - Train loss: 0.0005 - Train Accuracy: 1.0000 - Val loss: 0.0011 - Val accuracy: 0.9880\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Train and validate for each fold\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(train_dataset)):\n",
    "    print(f'Fold {fold + 1}/{k}')\n",
    "    \n",
    "    # Create subset datasets and dataloaders for this fold\n",
    "    train_subset = Subset(train_dataset, train_indices)\n",
    "    kfold_val_subset = Subset(train_dataset, val_indices)\n",
    "    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "    kfold_val_loader = DataLoader(kfold_val_subset, batch_size=64, shuffle=False)\n",
    "    # Model\n",
    "    model = ResNet9()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "#   optimizer = optim.Adam(model.parameters(), learning_rate)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    \n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    kfold_val_losses = []\n",
    "    kfold_val_accuracies = []\n",
    "    \n",
    "    # Train and validate for this fold\n",
    "    for epoch in range(number_of_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer)\n",
    "        kfold_val_loss = train(model,kfold_val_loader,criterion,optimizer)\n",
    "        val_loss = train(model,val_dataloader,criterion,optimizer)\n",
    "        \n",
    "        # Loss\n",
    "        train_losses.append(train_loss)\n",
    "        kfold_val_losses.append(kfold_val_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        preds, labels = evaluate(model, train_loader)\n",
    "        train_accuracy = get_accuracy(preds, labels)\n",
    "\n",
    "        preds, labels = evaluate(model, kfold_val_loader)\n",
    "        kfold_val_accuracy = get_accuracy(preds, labels)\n",
    "\n",
    "        preds, labels = evaluate(model, val_dataloader)\n",
    "        val_accuracy = get_accuracy(preds, labels)\n",
    "\n",
    "        # Accuracies\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        kfold_val_accuracies.append(kfold_val_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        print(f'Epoch {epoch + 1} - Train loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - Val loss: {val_loss:.4f} - Val accuracy: {val_accuracy:.4f}')\n",
    "    \n",
    "    # Saving the Current Fold Model\n",
    "    torch.save(model, f'fold{fold}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49285d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "torch.save(model, './saved_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71cfac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the losses\n",
    "def plot_losses():\n",
    "    matplot.plot(train_losses, '-bx')\n",
    "    matplot.plot(val_losses, '-rx')\n",
    "    matplot.xlabel('epoch')\n",
    "    matplot.ylabel('loss')\n",
    "    matplot.legend(['Training', 'Validation'])\n",
    "    matplot.title('Loss vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c1a0de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7c9d1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet9(\n",
       "  (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Identity()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Identity()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the model\n",
    "test_model = ResNet9()\n",
    "PATH = './fold2.pth'\n",
    "test_model = torch.load(PATH)\n",
    "test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d96724dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5570, device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating Test Data\n",
    "preds, labels = evaluate(test_model, test_dataloader)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = get_accuracy(preds, labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-1 SCORE\n",
    "f1_score = get_f1score(preds, labels)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c1453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "confusion_matrix = np.zeros((num_of_classes, num_of_classes))\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(test_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = test_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "matplot.figure(figsize=(12,7))\n",
    "\n",
    "df_cm = pd.DataFrame((confusion_matrix/(np.sum(confusion_matrix, axis=1))), index=classes, columns=classes)\n",
    "heatmap = sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f726f945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
